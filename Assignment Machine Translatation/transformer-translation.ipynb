{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8656885,"sourceType":"datasetVersion","datasetId":5186205},{"sourceId":8694740,"sourceType":"datasetVersion","datasetId":5214124},{"sourceId":8695461,"sourceType":"datasetVersion","datasetId":5214606},{"sourceId":8739746,"sourceType":"datasetVersion","datasetId":5247083},{"sourceId":8845149,"sourceType":"datasetVersion","datasetId":5323671}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport spacy\nimport torchtext\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\n\nfrom torch import optim\nfrom torch.optim import Adam\n\nimport time\nimport math\n\nimport html\n\nfrom collections import Counter\nfrom string import punctuation\nfrom nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\nfrom itertools import product","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:46.070088Z","iopub.execute_input":"2024-07-03T01:49:46.070717Z","iopub.status.idle":"2024-07-03T01:49:56.092495Z","shell.execute_reply.started":"2024-07-03T01:49:46.070683Z","shell.execute_reply":"2024-07-03T01:49:56.091529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Embeddings","metadata":{}},{"cell_type":"markdown","source":"## Positional Embeddings","metadata":{}},{"cell_type":"code","source":"class PositionalEmbedding(nn.Module):\n    def __init__(self, max_len, embedding_dim, device):\n        super().__init__()\n        \n        self.d = embedding_dim\n\n        self.embedd = torch.zeros(max_len, self.d, device = device)\n        self.embedd.requires_grad = False\n\n        pos = torch.arange(0, max_len, device = device)\n        pos = pos.float().unsqueeze(dim=1)\n\n        i_odd = torch.arange(1, self.d, step=2, device = device).float()\n        i_even = torch.arange(0, self.d, step=2, device = device).float()\n\n        self.embedd[:,0::2] = torch.sin(pos / (10000 ** (i_even / self.d)))\n        self.embedd[:,1::2] = torch.cos(pos / (10000 ** ((i_odd - 1) / self.d)))\n\n    def forward(self, X):\n        '''\n        Đầu vào:\n        X: batch_size * N\n        Đầu ra:\n        một ma trận vị trí có kích thước là N * embedding_dim\n        '''\n        \n        _, seq_len = X.size()\n\n        out = self.embedd[:seq_len,:]\n\n        return out # batch_size * N * d\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.094286Z","iopub.execute_input":"2024-07-03T01:49:56.094772Z","iopub.status.idle":"2024-07-03T01:49:56.104354Z","shell.execute_reply.started":"2024-07-03T01:49:56.094745Z","shell.execute_reply":"2024-07-03T01:49:56.103324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokens Embedding","metadata":{}},{"cell_type":"code","source":"class TokenEmbedding(nn.Embedding):\n    def __init__(self, vocab_size, embedding_dim):\n        super().__init__(vocab_size, embedding_dim, padding_idx=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.105646Z","iopub.execute_input":"2024-07-03T01:49:56.105992Z","iopub.status.idle":"2024-07-03T01:49:56.115983Z","shell.execute_reply.started":"2024-07-03T01:49:56.105963Z","shell.execute_reply":"2024-07-03T01:49:56.115196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformer Embedding","metadata":{}},{"cell_type":"code","source":"class TransformerEmbedding(nn.Module):\n    def __init__(self, max_len, vocab_size, embedding_dim, drop_prob, device) -> None:\n        super().__init__()\n        self.tok_emb = TokenEmbedding(vocab_size, embedding_dim)\n        self.pos_emb = PositionalEmbedding(max_len, embedding_dim, device)\n        self.drop_out = nn.Dropout(drop_prob)\n    def forward(self,X):\n        tok_emb = self.tok_emb(X)\n        pos_emb = self.pos_emb(X)\n        return self.drop_out(tok_emb + pos_emb)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.118269Z","iopub.execute_input":"2024-07-03T01:49:56.118567Z","iopub.status.idle":"2024-07-03T01:49:56.128564Z","shell.execute_reply.started":"2024-07-03T01:49:56.118536Z","shell.execute_reply":"2024-07-03T01:49:56.127656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Layers","metadata":{}},{"cell_type":"markdown","source":"## FeedForwardNetwork","metadata":{}},{"cell_type":"code","source":"\nclass FeedForwardNetwork(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, drop_out = 0.3):\n        super().__init__()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n        \n        self.activation = nn.ReLU()\n        \n        self.drop_out = nn.Dropout(drop_out)\n        \n        self.input_layer = nn.Linear(self.input_dim, self.hidden_dim)\n        \n        self.output_layer = nn.Linear(self.hidden_dim, self.output_dim)\n    \n    def forward(self, X):\n        #X: batch_size * N * d\n        \n        X_in = self.drop_out(\n            self.activation(\n                self.input_layer(X)\n            )\n        )\n        \n        X_out = self.output_layer(\n            X_in\n        )\n        \n        return X_out","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.129696Z","iopub.execute_input":"2024-07-03T01:49:56.129959Z","iopub.status.idle":"2024-07-03T01:49:56.142856Z","shell.execute_reply.started":"2024-07-03T01:49:56.129936Z","shell.execute_reply":"2024-07-03T01:49:56.141918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multihead Attention","metadata":{}},{"cell_type":"code","source":"\nclass MultiheadAttention(nn.Module):\n    def __init__(self,num_head, embedding_dim, dim_key, dim_value, device, masked = True):\n        super().__init__()\n        self.h = num_head\n        self.d = embedding_dim\n        self.d_k = dim_key\n        self.d_v = dim_value\n        self.masked = masked\n        self.device = device\n        \n        self.hWQs = nn.ModuleList()\n        for h_i in range(self.h):\n            self.hWQs.append(nn.Linear(self.d, self.d_k))\n        \n        self.hWKs = nn.ModuleList()\n        for h_i in range(self.h):\n            self.hWKs.append(nn.Linear(self.d, self.d_k))\n        \n        self.hWVs = nn.ModuleList()\n        for h_i in range(self.h):\n            self.hWVs.append(nn.Linear(self.d, self.d_v))\n            \n        self.WO = nn.Linear(self.h * self.d_v, self.d)\n            \n    def forward(self, X1, X2 = None, X3 = None):\n        '''\n        X1,X2,X3 correspond to Q,K,V\n        '''\n        # X: batch_size * N * d\n        if X2 is None and X3 is None:\n            X2 = X1\n            X3 = X1\n            \n        num_batchs = X1.size(0)\n        \n        heads = []\n        for h_i in range(self.h):\n            Q = self.hWQs[h_i](X1)\n            # print(Q.size())\n            K = self.hWKs[h_i](X2)\n            V = self.hWVs[h_i](X3)\n            \n            softmax = nn.Softmax(dim = -1)\n            if self.masked:\n                mask_matrix = torch.triu(torch.ones((num_batchs, Q.size(-2), K.size(-2)), device = self.device) * -float('inf'), diagonal = 1)\n            else:\n                mask_matrix = torch.zeros((num_batchs, Q.size(-2), K.size(-2)), device = self.device)\n            \n            head_i = torch.matmul(\n                softmax(\n                    (torch.matmul(Q, K.transpose(-1, -2)) + mask_matrix) / \n                    torch.sqrt(torch.tensor(self.d_k))\n                ),\n                V\n            )\n            # print(head_i)\n            heads.append(head_i)\n        \n        A = self.WO(torch.concat(heads, dim = -1))\n        \n        return A","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.143978Z","iopub.execute_input":"2024-07-03T01:49:56.144279Z","iopub.status.idle":"2024-07-03T01:49:56.158591Z","shell.execute_reply.started":"2024-07-03T01:49:56.144256Z","shell.execute_reply":"2024-07-03T01:49:56.157764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Norm","metadata":{}},{"cell_type":"code","source":"class Norm(nn.Module):\n    def __init__(self, embedding_dim, eps = 1e-5):\n        super().__init__()\n        self.d = embedding_dim\n        self.gamma = nn.Parameter(torch.ones(self.d))\n        self.beta = nn.Parameter(torch.zeros(self.d))\n        self.eps = eps\n    \n    def forward(self, X):\n        #X: batch_size * N * d\n        mu = torch.mean(X, dim = -1, keepdim = True)\n        sigma = torch.sqrt(\n            torch.var(X, dim = -1, unbiased = False, keepdim = True) + \n            self.eps\n        )\n        \n        X_norm = (X - mu) / sigma\n        \n        out = self.gamma * X_norm + self.beta\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.159679Z","iopub.execute_input":"2024-07-03T01:49:56.160271Z","iopub.status.idle":"2024-07-03T01:49:56.173954Z","shell.execute_reply.started":"2024-07-03T01:49:56.160240Z","shell.execute_reply":"2024-07-03T01:49:56.173149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Block","metadata":{}},{"cell_type":"markdown","source":"## Encoder Block","metadata":{}},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self,num_head, embedding_dim, dim_key, dim_value, feed_forward_dim, device, drop_prob = 0.3):\n        super().__init__()\n        self.h = num_head\n        self.d = embedding_dim\n        self.d_ff = feed_forward_dim\n        self.d_k = dim_key\n        self.d_v = dim_value\n        \n        self.MultiheadAttention = MultiheadAttention(\n            self.h, self.d, self.d_k, self.d_v, device,False\n        )\n        self.Norm1 = Norm(self.d)\n        self.drop_out1 = nn.Dropout(p=drop_prob)\n\n        self.FFN = FeedForwardNetwork(\n            self.d,self.d_ff,self.d\n        )\n        self.Norm2 = Norm(self.d)\n        self.drop_out2 = nn.Dropout(p=drop_prob)\n        \n    def forward(self, X):\n        #X: batch_size * N * d\n        T_1 = self.MultiheadAttention(X)\n        T_1 = self.drop_out1(T_1)\n        \n        T_2 = X + T_1\n        \n        T_3 = self.Norm1(T_2)\n        \n        T_4 = self.FFN(T_3)\n        T_4 = self.drop_out2(T_4)\n        \n        T_5 = T_4 + T_3\n        \n        H = self.Norm2(T_5)\n        \n        return H\n        ","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.175089Z","iopub.execute_input":"2024-07-03T01:49:56.175912Z","iopub.status.idle":"2024-07-03T01:49:56.188897Z","shell.execute_reply.started":"2024-07-03T01:49:56.175888Z","shell.execute_reply":"2024-07-03T01:49:56.188247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decoder Block","metadata":{}},{"cell_type":"code","source":"\nclass DecoderBlock(nn.Module):\n    '''\n    required input for DecoderBlock: pre-tokens, \n    '''\n    def __init__(self,num_head, embedding_dim, dim_key, dim_value, feed_forward_dim, device, drop_prob = 0.3):\n        super().__init__()\n        self.h = num_head\n        self.d = embedding_dim\n        self.d_ff = feed_forward_dim\n        self.d_k = dim_key\n        self.d_v = dim_value\n\n        self.SelfAttentionLayer = MultiheadAttention(self.h, self.d, self.d_k, self.d_v, device)\n        self.Norm1 = Norm(self.d)\n        self.drop_out1 = nn.Dropout(drop_prob)\n\n        self.CrossAttentionLayer = MultiheadAttention(self.h, self.d, self.d_k, self.d_v, device, False)\n        self.Norm2 = Norm(self.d)\n        self.drop_out2 = nn.Dropout(drop_prob)\n\n        self.FFN = FeedForwardNetwork(self.d, self.d_ff, self.d)\n        self.Norm3 = Norm(self.d)\n        self.drop_out3 = nn.Dropout(drop_prob)\n        \n    def forward(self, X, H_enc):\n        '''\n        X: batch_size * 1 * d\n        '''\n        if H_enc is None:\n            raise ValueError(\"In Decoder Transformer, H_enc must be not None\")\n\n        X1 = self.SelfAttentionLayer(X)\n        X1 = self.drop_out1(X1)\n\n        X2 = X1 + X\n\n        X3 = self.Norm1(X2)\n\n        X4 = self.CrossAttentionLayer(X3, H_enc, H_enc)\n        X4 = self.drop_out2(X4)\n\n        X5 = X4 + X3\n\n        X6 = self.Norm2(X5)\n\n        X7 = self.FFN(X6)\n        X7 = self.drop_out3(X7)\n\n        X8 = X7 + X6\n\n        out = self.Norm3(X8)\n\n        return out\n        ","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.189893Z","iopub.execute_input":"2024-07-03T01:49:56.190209Z","iopub.status.idle":"2024-07-03T01:49:56.201039Z","shell.execute_reply.started":"2024-07-03T01:49:56.190187Z","shell.execute_reply":"2024-07-03T01:49:56.200133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"markdown","source":"## Encoder","metadata":{}},{"cell_type":"code","source":"\nclass Encoder(nn.Module):\n    def __init__(self, num_head, embedding_dim, dim_key, dim_value, feed_forward_dim, n_blocks, vocab_size, max_len, device, drop_prob = 0.3):\n        super().__init__()\n        self.h = num_head\n        self.d = embedding_dim\n        self.d_ff = feed_forward_dim\n        self.d_k = dim_key\n        self.d_v = dim_value\n        self.n_blocks = n_blocks\n        self.emb = TransformerEmbedding(max_len, vocab_size, self.d, drop_prob, device)\n        \n        self.list_transformer_blocks = nn.ModuleList()\n        for block_i in range(self.n_blocks):\n            self.list_transformer_blocks.append(\n                EncoderBlock(\n                    self.h, self.d, self.d_k, self.d_v, self.d_ff, device, drop_prob\n                )\n            )\n        \n    def forward(self, X):\n        #X: batch_size * N\n        X_out = self.emb(X)\n        for block_i in self.list_transformer_blocks:\n            X_out = block_i(X_out)\n            \n        return X_out\n        ","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.204339Z","iopub.execute_input":"2024-07-03T01:49:56.204650Z","iopub.status.idle":"2024-07-03T01:49:56.215865Z","shell.execute_reply.started":"2024-07-03T01:49:56.204628Z","shell.execute_reply":"2024-07-03T01:49:56.214977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decoder","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, num_head, embedding_dim, dim_key, dim_value, feed_forward_dim, n_blocks, vocab_size, max_len, device, drop_prob = 0.3):\n        super().__init__()\n        self.h = num_head\n        self.d = embedding_dim\n        self.d_ff = feed_forward_dim\n        self.d_k = dim_key\n        self.d_v = dim_value\n        self.n_blocks = n_blocks\n        self.output_dim = vocab_size\n\n        self.embedding = TransformerEmbedding(max_len, vocab_size, self.d, drop_prob, device)\n        self.list_decoder_blocks = nn.ModuleList()\n        for decoder_block_i in range(self.n_blocks):\n            self.list_decoder_blocks.append(\n                DecoderBlock(\n                    self.h, self.d, self.d_k, self.d_v, self.d_ff, device, drop_prob\n                )\n            )\n        \n        self.linear = nn.Linear(self.d, self.output_dim)\n\n    def forward(self, X, H_enc):\n        X1 = self.embedding(X)\n\n        for decoder_block_i in self.list_decoder_blocks:\n            X1 = decoder_block_i(X1, H_enc)\n        \n        X2 = self.linear(X1)\n\n        return X2","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.216862Z","iopub.execute_input":"2024-07-03T01:49:56.217193Z","iopub.status.idle":"2024-07-03T01:49:56.230060Z","shell.execute_reply.started":"2024-07-03T01:49:56.217163Z","shell.execute_reply":"2024-07-03T01:49:56.229219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformer","metadata":{}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(\n        self, num_head, embedding_dim, dim_key, dim_value, feed_forward_dim, n_blocks, enc_vocab_size, dec_vocab_size, max_len, device, drop_prob = 0.3\n    ) -> None:\n        super().__init__()\n        self.encoder = Encoder(\n            num_head, embedding_dim, dim_key, dim_value, feed_forward_dim, n_blocks, enc_vocab_size, max_len, device, drop_prob\n        )\n        self.decoder = Decoder(\n            num_head, embedding_dim, dim_key, dim_value, feed_forward_dim, n_blocks, dec_vocab_size, max_len, device, drop_prob\n        )\n    def forward(self, source, target = None):\n\n        H = self.encoder(source)\n        \n        output = self.decoder(target, H)\n\n        return output\n    \n    def predict(self, input):\n        pass","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.231117Z","iopub.execute_input":"2024-07-03T01:49:56.231478Z","iopub.status.idle":"2024-07-03T01:49:56.243251Z","shell.execute_reply.started":"2024-07-03T01:49:56.231447Z","shell.execute_reply":"2024-07-03T01:49:56.242469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conf","metadata":{}},{"cell_type":"code","source":"\n# GPU device setting\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# model parameter setting\nbatch_size = 128\nmax_len = 64\nd_model = 512\nd_k = 64\nd_v = 64\nn_layers = 6\nn_heads = 8\nffn_hidden = 2048\ndrop_prob = 0.1\n\n# optimizer parameter setting\ninit_lr = 1e-5\nfactor = 0.9\nadam_eps = 5e-9\npatience = 10\nwarmup = 100\nepoch = 1000\nclip = 1.0\nweight_decay = 5e-4\ninf = float('inf')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.244240Z","iopub.execute_input":"2024-07-03T01:49:56.244538Z","iopub.status.idle":"2024-07-03T01:49:56.253669Z","shell.execute_reply.started":"2024-07-03T01:49:56.244516Z","shell.execute_reply":"2024-07-03T01:49:56.252834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Util","metadata":{}},{"cell_type":"code","source":"def choice_sample_p(data, size):\n    np.random.seed(2206)\n    sample_p_idx = np.random.choice(np.arange(len(data)), size = size, replace= False)\n    sample_p_choice = np.isin(np.arange(len(data)), sample_p_idx)\n    sample_p_data = np.array(data)[sample_p_choice]\n    return sample_p_data\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n\ndef get_bleu(hypotheses, reference):\n    \"\"\"Get validation BLEU score for dev set.\"\"\"\n    smoothie = SmoothingFunction().method1\n    bleu_score = sentence_bleu([reference], hypotheses, smoothing_function=smoothie)*100\n    return bleu_score\n\ndef idx_to_word(x, vocab):\n    words = []\n    for i in x:\n        word = vocab.get_itos()[i]\n        if '<' not in word:\n            words.append(word)\n    words = \" \".join(words)\n    return words","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.255010Z","iopub.execute_input":"2024-07-03T01:49:56.255390Z","iopub.status.idle":"2024-07-03T01:49:56.267916Z","shell.execute_reply.started":"2024-07-03T01:49:56.255362Z","shell.execute_reply":"2024-07-03T01:49:56.267143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"eos_token = \"<eos>\"\nsos_token = \"<sos>\"\npad_token = \"<pad>\"\nunk_token = \"<unk>\"\nmax_length = max_len\nmin_freq = 2\n\n# đọc file trainen, trainvi, tạo thành các list\ndef load_file(file_path):\n    sentences = []\n    with open(file_path, 'r') as file:\n        content = file.read()\n        sentences = content.split('\\n')\n    new_sentences = []\n    for sentence in sentences:\n        tokens = []\n        for token in sentence.split():\n            if token not in punctuation:\n                tokens.append(token)\n        new_sentence = ' '.join(tokens)\n        new_sentences.append(new_sentence)\n    return new_sentences\n\ndef tokenizer(sentences, lower, eos_token, sos_token, max_length):\n    return [sos_token] + html.unescape(\n        sentences.lower() if lower else sentences\n    ).split(' ')[:(max_length - 2)] + [eos_token]\n\n# train\ntrain_en_file = \"/kaggle/input/data-translation-133k/data/train/train.en\"\ntrain_vi_file = \"/kaggle/input/data-translation-133k/data/train/train.vi\"\n\ntrain_en = load_file(train_en_file)\ntrain_vi = load_file(train_vi_file)\n\ntrain_en_tokens = [tokenizer(sent,True, eos_token, sos_token, max_length) for sent in train_en]\ntrain_vi_tokens = [tokenizer(sent,True, eos_token, sos_token, max_length) for sent in train_vi]\n\n# test\ntest_en_file = \"/kaggle/input/data-translation-133k/data/test/test.en\"\ntest_vi_file = \"/kaggle/input/data-translation-133k/data/test/test.vi\"\n\ntest_en = load_file(test_en_file)\ntest_vi = load_file(test_vi_file)\n\ntest_en_tokens = [tokenizer(sent,True, eos_token, sos_token, max_length) for sent in test_en]\ntest_vi_tokens = [tokenizer(sent,True, eos_token, sos_token, max_length) for sent in test_vi]\n\n#dev\ndev_en_file = \"/kaggle/input/data-translation-133k/data/dev/dev.en\"\ndev_vi_file = \"/kaggle/input/data-translation-133k/data/dev/dev.vi\"\n\ndev_en = load_file(dev_en_file)\ndev_vi = load_file(dev_vi_file)\n\ndev_en_tokens = [tokenizer(sent,True, eos_token, sos_token, max_length) for sent in dev_en]\ndev_vi_tokens = [tokenizer(sent,True, eos_token, sos_token, max_length) for sent in dev_vi]\n\n# vocab\nspecial_tokens = [\n    unk_token,\n    pad_token,\n    sos_token,\n    eos_token\n]\nen_vocab = torchtext.vocab.build_vocab_from_iterator(\n    train_en_tokens, min_freq,special_tokens,\n)\nvi_vocab = torchtext.vocab.build_vocab_from_iterator(\n    train_vi_tokens, min_freq, special_tokens\n)\n\nassert en_vocab[unk_token] == vi_vocab[unk_token]\nassert en_vocab[pad_token] == vi_vocab[pad_token]\n\nunk_index = en_vocab[unk_token]\npad_index = en_vocab[pad_token]\n\nen_vocab.set_default_index(unk_index)\nvi_vocab.set_default_index(unk_index)\n\nen_vocab_size = len(en_vocab)\nvi_vocab_size = len(vi_vocab)\n\n#train\ntrain_en_ids = [en_vocab.lookup_indices(toks) for toks in train_en_tokens]\ntrain_vi_ids = [vi_vocab.lookup_indices(toks) for toks in train_vi_tokens]\n\n#test\ntest_en_ids = [en_vocab.lookup_indices(toks) for toks in test_en_tokens]\ntest_vi_ids = [vi_vocab.lookup_indices(toks) for toks in test_vi_tokens]\n\n#dev\ndev_en_ids = [en_vocab.lookup_indices(toks) for toks in dev_en_tokens]\ndev_vi_ids = [vi_vocab.lookup_indices(toks) for toks in dev_vi_tokens]\n\nclass Bitext(Dataset):\n    def __init__(self, src, trg) -> None:\n        super().__init__()\n        self.src = src\n        self.trg = trg\n    def __len__(self):\n        return len(self.src)\n    def __getitem__(self, index):\n        return self.src[index], self.trg[index]\n    \ntrain_dataset = Bitext(train_en_ids, train_vi_ids)\ntest_dataset = Bitext(test_en_ids, test_vi_ids)\ndev_dataset = Bitext(dev_en_ids, dev_vi_ids)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:49:56.269321Z","iopub.execute_input":"2024-07-03T01:49:56.269793Z","iopub.status.idle":"2024-07-03T01:50:03.494224Z","shell.execute_reply.started":"2024-07-03T01:49:56.269763Z","shell.execute_reply":"2024-07-03T01:50:03.493434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"def get_collate_fn(pad_index):\n    def collate_fn(batch):\n        src, trg = zip(*batch)\n\n        src = [torch.LongTensor(toks) for toks in src]\n        trg = [torch.LongTensor(toks) for toks in trg]\n        \n        src = nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=pad_index)\n        trg = nn.utils.rnn.pad_sequence(trg, batch_first=True, padding_value=pad_index)\n\n        return src, trg\n\n    return collate_fn\n\ndef get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n    collate_fn = get_collate_fn(pad_index)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        collate_fn=collate_fn,\n        shuffle=shuffle\n    )\n    return data_loader\n\ntrain_dataloader = get_data_loader(\n    train_dataset, batch_size, pad_index, True\n)\n\ntest_dataloader = get_data_loader(\n    test_dataset, batch_size, pad_index, True\n)\n\ndev_dataloader = get_data_loader(\n    dev_dataset, batch_size, pad_index, True\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:03.495229Z","iopub.execute_input":"2024-07-03T01:50:03.495485Z","iopub.status.idle":"2024-07-03T01:50:03.504281Z","shell.execute_reply.started":"2024-07-03T01:50:03.495463Z","shell.execute_reply":"2024-07-03T01:50:03.503289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run","metadata":{}},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\ndef initialize_weights(m):\n    if hasattr(m, 'weight') and m.weight.dim() > 1:\n        nn.init.kaiming_uniform(m.weight.data)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:03.505308Z","iopub.execute_input":"2024-07-03T01:50:03.505571Z","iopub.status.idle":"2024-07-03T01:50:03.519433Z","shell.execute_reply.started":"2024-07-03T01:50:03.505549Z","shell.execute_reply":"2024-07-03T01:50:03.518659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Transformer(\n    num_head= n_heads, \n    embedding_dim = d_model, \n    dim_key = d_k, \n    dim_value= d_v, \n    feed_forward_dim = ffn_hidden, \n    n_blocks= n_layers, \n    enc_vocab_size = en_vocab_size, \n    dec_vocab_size= vi_vocab_size, \n    max_len = max_len, \n    device = device,\n    drop_prob = drop_prob\n).to(device)\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:03.520632Z","iopub.execute_input":"2024-07-03T01:50:03.521248Z","iopub.status.idle":"2024-07-03T01:50:04.713675Z","shell.execute_reply.started":"2024-07-03T01:50:03.521217Z","shell.execute_reply":"2024-07-03T01:50:04.712699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.apply(initialize_weights)\noptimizer = Adam(params=model.parameters(),\n                 lr=init_lr,\n                 weight_decay=weight_decay,\n                 eps=adam_eps)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:04.715215Z","iopub.execute_input":"2024-07-03T01:50:04.715575Z","iopub.status.idle":"2024-07-03T01:50:05.509633Z","shell.execute_reply.started":"2024-07-03T01:50:04.715541Z","shell.execute_reply":"2024-07-03T01:50:05.508674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n                                                 verbose=True,\n                                                 factor=factor,\n                                                 patience=patience)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:05.510871Z","iopub.execute_input":"2024-07-03T01:50:05.511524Z","iopub.status.idle":"2024-07-03T01:50:05.516881Z","shell.execute_reply.started":"2024-07-03T01:50:05.511489Z","shell.execute_reply":"2024-07-03T01:50:05.515957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, iterator, optimizer, criterion, clip, device):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(iterator):\n        src, trg = batch\n        src = src.to(device)\n        trg = trg.to(device)\n\n        optimizer.zero_grad()\n        output = model(src, trg[:, :-1])\n        output_reshape = output.contiguous().view(-1, output.shape[-1])\n        trg = trg[:, 1:].contiguous().view(-1)\n\n        loss = criterion(output_reshape, trg)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        print('step :', round((i / len(iterator)) * 100, 2), '% , loss :', loss.item())\n\n    return epoch_loss / len(iterator)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:05.518047Z","iopub.execute_input":"2024-07-03T01:50:05.518329Z","iopub.status.idle":"2024-07-03T01:50:05.531216Z","shell.execute_reply.started":"2024-07-03T01:50:05.518307Z","shell.execute_reply":"2024-07-03T01:50:05.530378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    batch_bleu = []\n    with torch.no_grad():\n        for i, batch in enumerate(iterator):\n            src, trg = batch\n            src = src.to(device)\n            trg = trg.to(device)\n            \n            output = model(src, trg[:, :-1])\n            output_reshape = output.contiguous().view(-1, output.shape[-1])\n            trg = trg[:, 1:].contiguous().view(-1)\n\n            loss = criterion(output_reshape, trg)\n            epoch_loss += loss.item()\n\n            total_bleu = []\n\n            src, trg = batch\n            for j in range(len(trg)):\n                try:\n                    trg_words = idx_to_word(trg[j], vi_vocab)\n                    output_words = output[j].argmax(1)\n                    output_words = idx_to_word(output_words, vi_vocab)\n                    ble = get_bleu(hypotheses=output_words.split(), reference=trg_words.split())\n                    total_bleu.append(ble)\n                except:\n                    pass\n\n            batch_bleu.append(np.mean(total_bleu))\n\n    batch_bleu = np.mean(batch_bleu)\n    return epoch_loss / len(iterator), batch_bleu","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:05.532283Z","iopub.execute_input":"2024-07-03T01:50:05.532993Z","iopub.status.idle":"2024-07-03T01:50:05.542922Z","shell.execute_reply.started":"2024-07-03T01:50:05.532958Z","shell.execute_reply":"2024-07-03T01:50:05.542042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from util.util import *\ndef run(model, total_epoch, best_loss, device):\n    train_losses, test_losses, bleus = [], [], []\n    for step in range(total_epoch):\n        start_time = time.time()\n        train_loss = train(model, train_dataloader, optimizer, criterion, clip, device)\n        valid_loss, bleu = evaluate(model, dev_dataloader, criterion, device) # tính chỉ số bleu trên mỗi epoch\n        end_time = time.time()\n\n        if step > warmup:\n            scheduler.step(valid_loss)\n\n        train_losses.append(train_loss)\n        test_losses.append(valid_loss)\n        bleus.append(bleu)\n        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n        if valid_loss < best_loss:\n            best_loss = valid_loss\n#             torch.save(model.state_dict(), '/kaggle/working/model-{0}.pt'.format(valid_loss))\n        if step % 20 == 0:\n            torch.save(model.state_dict(), '/kaggle/working/model-{0}.pt'.format(step))\n\n        f = open('/kaggle/working/train_loss.txt', 'w') # lưu lại train_loss để vẽ đồ thị\n        f.write(str(train_losses))\n        f.close()\n\n        f = open('/kaggle/working/bleu.txt', 'w')\n        f.write(str(bleus))\n        f.close()\n\n        f = open('/kaggle/working/valid_loss.txt', 'w') # lưu lại valid_loss để vẽ đồ thị\n        f.write(str(test_losses))\n        f.close()\n\n        print(f'Epoch: {step + 1} | Time: {epoch_mins}m {epoch_secs}s')\n        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n        print(f'\\tVal Loss: {valid_loss:.3f} |  Val PPL: {math.exp(valid_loss):7.3f}')\n        print(f'\\tBLEU Score: {bleu:.3f}')\n    # tính loss, bleu trên tập test:\n    test_loss, bleu_test = evaluate(model, test_dataloader, criterion, device)\n    print(f\"\\tTest Loss: {test_loss:.3f} | Bleu Score of Test: {bleu_test:.3f}\")\n    f = open('/kaggle/working/result_test_loss.txt', 'w')\n    f.write(str(test_loss))\n    f.close()\n\n    f = open('/kaggle/working/result_Bleu_Test.txt', 'w')\n    f.write(str(bleu_test))\n    f.close()\n#     return train_losses, test_losses, bleus\n","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:05.545153Z","iopub.execute_input":"2024-07-03T01:50:05.545480Z","iopub.status.idle":"2024-07-03T01:50:05.558050Z","shell.execute_reply.started":"2024-07-03T01:50:05.545451Z","shell.execute_reply":"2024-07-03T01:50:05.557329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epoch = 1\nrun(model = model,total_epoch = epoch, best_loss=inf, device = device)\ntorch.save(model.state_dict(), '/kaggle/working/model-official.pt')\n# model = torch.load('result/model-180.pt')\n# model.load_state_dict(torch.load('result/model-180.pt'))\n# epoch = 1\n# run(model = model,total_epoch = epoch, best_loss=inf, device = device)\n# model.load_state_dict(model_state_dict)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T01:50:05.559061Z","iopub.execute_input":"2024-07-03T01:50:05.559317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = torch.load('result/model-180.pt')\n# model.load_state_dict(torch.load('/kaggle/input/model-transformer-translation/model-980.pt'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dịch: \nfor batch in test_dataloader:\n    src, trg = batch\n    src = src.to(device)\n    trg = trg.to(device)\n    break\noutput = model(src, trg[:, :-1])\n\ntrg_words = idx_to_word(trg[0], vi_vocab)\noutput_words = output[0].argmax(1)\noutput_words = idx_to_word(output_words, vi_vocab)\nprint(f\"Bản gốc: {trg_words} \\n Bản dịch: {output_words}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}